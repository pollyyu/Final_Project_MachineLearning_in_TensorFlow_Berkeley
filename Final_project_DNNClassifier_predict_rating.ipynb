{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from absl import flags\n",
    "\n",
    "learning_rate = 0.000000001\n",
    "\n",
    "dataset = \"epi_r.csv\"\n",
    "datapath = \"documents/ml_tf/final_project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_and_clean_file(dataset, datapath):\n",
    "    # set working directory and download csv file; save as data\n",
    "    os.chdir(datapath)\n",
    "    data = read_csv(dataset)\n",
    "\n",
    "    # clean and order file\n",
    "    data.dropna(inplace=True) # remove NAs\n",
    "    data.reset_index(inplace=True) # resetting index\n",
    "    data.drop('index', axis='columns', inplace=True)\n",
    "\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def input_columns(dataset,datapath):\n",
    "    data = download_and_clean_file(dataset,datapath)\n",
    "    \n",
    "    # Preparing columns\n",
    "    data.head(1)              # reads the first line\n",
    "    rows = len(data)          # counts the number of rows in the file\n",
    "    shape = data.shape        # shows the shape\n",
    "    \n",
    "    \n",
    "    features = []\n",
    "    label = []\n",
    "\n",
    "    rating = data['rating'] # label\n",
    "    \n",
    "    calories = data['calories']\n",
    "    protein = data['protein']\n",
    "    fat = data['fat']\n",
    "    sodium = data['sodium']\n",
    "\n",
    "    dessert = data['dessert'] # possible label #2\n",
    "    peanut_free = data['peanut free']\n",
    "    soy_free = data['soy free']\n",
    "    tree_nut_free = data['tree nut free']\n",
    "    vegetarian = data['vegetarian']\n",
    "    gourmet = data['gourmet']\n",
    "    kosher = data['kosher']\n",
    "    pescatarian = data['pescatarian']\n",
    "    quick_easy = data['quick & easy']\n",
    "    wheat_gluten_free = data['wheat/gluten-free']\n",
    "    bake = data['bake']\n",
    "    summer = data['summer']\n",
    "    dairy_free = data['dairy free']\n",
    "    side = data['side']\n",
    "    no_sugar_added = data['no sugar added']\n",
    "    winter = data['winter']\n",
    "    fall = data['fall']\n",
    "    dinner = data['dinner']\n",
    "    sugar_conscious = data['sugar conscious']\n",
    "    healthy = data['healthy']\n",
    "    kidney_friendly = data['kidney friendly']\n",
    "    onion = data['onion']\n",
    "    tomato = data['tomato']\n",
    "    vegetable = data['vegetable']\n",
    "    milk_cream = data['milk/cream']\n",
    "    fruit = data['fruit']\n",
    "    vegan = data['vegan']\n",
    "    kid_friendly = data['kid-friendly']\n",
    "    egg = data['egg']\n",
    "    spring = data['spring']\n",
    "    herb = data['herb']\n",
    "    garlic = data['garlic']\n",
    "    salad = data['salad']\n",
    "    dairy = data['dairy']\n",
    "    thanksgiving = data['thanksgiving']\n",
    "    appetizer = data['appetizer']\n",
    "    lunch = data['lunch']\n",
    "    cheese = data['cheese']\n",
    "    chicken = data['chicken']\n",
    "    roast = data['roast']\n",
    "    no_cook = data['no-cook']\n",
    "    soup_stew = data['soup/stew']\n",
    "    cocktail_party = data['cocktail party']\n",
    "    ginger = data['ginger']\n",
    "    potato = data['potato']\n",
    "    chill = data['chill']\n",
    "    grill_barbecue = data['grill/barbecue']\n",
    "    lemon = data['lemon']\n",
    "    drink = data['drink']\n",
    "    sauce = data['sauce']\n",
    "    low_cal = data['low cal']\n",
    "    christm as = data['christmas']\n",
    "    high_fiber = data['high fiber']\n",
    "    food_processor = data['food processor']\n",
    "\n",
    "    for k in range(rows): # use loop to put it in the expected format\n",
    "        # appending features\n",
    "        features.append([calories[k],protein[k], fat[k], sodium[k], peanut_free[k],soy_free[k],tree_nut_free[k], \n",
    "        vegetarian[k],gourmet[k], kosher[k], pescatarian[k], quick_easy[k], wheat_gluten_free[k], bake[k], summer[k], \n",
    "        dessert[k], dairy_free[k],side[k], no_sugar_added[k], winter[k], fall[k], dinner[k], sugar_conscious[k], \n",
    "        healthy[k], kidney_friendly[k], onion[k], tomato[k], vegetable[k], milk_cream[k], fruit[k], vegan[k], \n",
    "        kid_friendly[k],egg[k], spring[k], herb[k], garlic[k], salad[k], dairy[k], thanksgiving[k], appetizer[k], lunch[k],\n",
    "        cheese[k], chicken[k], roast[k], no_cook[k], soup_stew[k], cocktail_party[k], ginger[k], potato[k],\n",
    "        chill[k], grill_barbecue[k], lemon[k], drink[k], sauce[k], low_cal[k], christmas[k], high_fiber[k], food_processor[k]])\n",
    "        \n",
    "        # creating classes for labels into 5 buckets, i.e less than 1 star rating is class 0, between 1 & 2 star rating is class 1\n",
    "        if rating[k] <= 1:\n",
    "            label.append(0)\n",
    "        elif rating[k]<=2:\n",
    "            label.append(1)\n",
    "        elif rating[k]<=3:\n",
    "            label.append(2)\n",
    "        elif rating[k]<=4:\n",
    "            label.append(3)\n",
    "        else: label.append(4)\n",
    "\n",
    "    return np.array(label), np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_data():\n",
    "# splitting data 70% train 30% test\n",
    "    label, features = input_columns()\n",
    "    train_len = int(len(features) * 0.7)\n",
    "    train_label, train_data = label[:train_len], features[:train_len]\n",
    "    test_label, test_data = label[train_len:], features[train_len:]\n",
    "    return train_label, train_data, test_label, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_estimator(model_type, model_dir):\n",
    "# Build 3 layer DNN with 100, 75, 50, 25 units respectively.\n",
    "    hidden_units = [100, 75, 50, 25]\n",
    "    \n",
    "    feature_columns = [tf.feature_column.numeric_column(\"x\",shape=[58])]\n",
    "    deep_columns = [tf.feature_column.numeric_column(\"deep\",shape=[4])]\n",
    "    wide_columns = [tf.feature_column.numeric_column(\"wide\",shape=[54])]\n",
    "    \n",
    "    if model_type == 'wide':\n",
    "        return tf.estimator.LinearClassifier(feature_columns=feature_columns,\n",
    "                                      n_classes=5,\n",
    "                                      model_dir=model_dir)\n",
    "        print(\"wide_model\")\n",
    "    elif model_type == 'deep':\n",
    "        return tf.estimator.DNNClassifier(feature_columns=feature_columns,\n",
    "                                      n_classes=5,\n",
    "                                      hidden_units = hidden_units,\n",
    "                                      model_dir=model_dir)\n",
    "        print(\"deep_model\")\n",
    "    else:\n",
    "        return tf.estimator.DNNLinearCombinedClassifier(\n",
    "                                          n_classes=5,\n",
    "                                          linear_feature_columns=wide_columns,\n",
    "                                          dnn_feature_columns=deep_columns,\n",
    "                                          dnn_hidden_units = hidden_units,\n",
    "                                          model_dir=model_dir)\n",
    "        print(\"wide+deep_model\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'test', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x12ee0b9b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "classifier = build_estimator(\"deep\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.estimator.inputs.numpy_io.numpy_input_fn.<locals>.input_fn>"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_fn = model_input(\"deep\")\n",
    "train_input_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into test/model.ckpt.\n",
      "INFO:tensorflow:loss = 10730.1, step = 1\n",
      "INFO:tensorflow:global_step/sec: 484.844\n",
      "INFO:tensorflow:loss = 262.146, step = 101 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.521\n",
      "INFO:tensorflow:loss = 173.012, step = 201 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 715.902\n",
      "INFO:tensorflow:loss = 135.98, step = 301 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 713.201\n",
      "INFO:tensorflow:loss = 156.776, step = 401 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 728.778\n",
      "INFO:tensorflow:loss = 139.107, step = 501 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 720.509\n",
      "INFO:tensorflow:loss = 126.317, step = 601 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 731.704\n",
      "INFO:tensorflow:loss = 145.465, step = 701 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 716.318\n",
      "INFO:tensorflow:loss = 144.1, step = 801 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 732.902\n",
      "INFO:tensorflow:loss = 136.371, step = 901 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 712.226\n",
      "INFO:tensorflow:loss = 144.661, step = 1001 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 745.484\n",
      "INFO:tensorflow:loss = 136.816, step = 1101 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 731.769\n",
      "INFO:tensorflow:loss = 149.145, step = 1201 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 734.786\n",
      "INFO:tensorflow:loss = 127.144, step = 1301 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 731.545\n",
      "INFO:tensorflow:loss = 136.845, step = 1401 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 725.69\n",
      "INFO:tensorflow:loss = 132.432, step = 1501 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 714.255\n",
      "INFO:tensorflow:loss = 123.245, step = 1601 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 717.299\n",
      "INFO:tensorflow:loss = 138.892, step = 1701 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 715.416\n",
      "INFO:tensorflow:loss = 141.613, step = 1801 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.549\n",
      "INFO:tensorflow:loss = 136.853, step = 1901 (0.152 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into test/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 138.615.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x12ee0b390>"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(input_fn=train_input_fn, steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Feature x is not in features dictionary.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-596-a66ee78191d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTest Accuracy: {0:f}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"model_type: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pyu18/anaconda/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, input_fn, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_convert_eval_steps_to_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pyu18/anaconda/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_evaluate_model\u001b[0;34m(self, input_fn, hooks, checkpoint_path, name)\u001b[0m\n\u001b[1;32m   1085\u001b[0m               input_fn, model_fn_lib.ModeKeys.EVAL))\n\u001b[1;32m   1086\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m-> 1087\u001b[0;31m           features, labels, model_fn_lib.ModeKeys.EVAL, self.config)\n\u001b[0m\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOSS_METRIC_KEY\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_metric_ops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pyu18/anaconda/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pyu18/anaconda/lib/python3.6/site-packages/tensorflow/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36m_model_fn\u001b[0;34m(features, labels, mode, config)\u001b[0m\n\u001b[1;32m    345\u001b[0m           \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m           \u001b[0minput_layer_partitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_layer_partitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m           config=config)\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     super(DNNClassifier, self).__init__(\n",
      "\u001b[0;32m/Users/pyu18/anaconda/lib/python3.6/site-packages/tensorflow/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36m_dnn_model_fn\u001b[0;34m(features, labels, mode, head, hidden_units, feature_columns, optimizer, activation_fn, dropout, input_layer_partitioner, config)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         input_layer_partitioner=input_layer_partitioner)\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     return head.create_estimator_spec(\n",
      "\u001b[0;32m/Users/pyu18/anaconda/lib/python3.6/site-packages/tensorflow/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36mdnn_logit_fn\u001b[0;34m(features, mode)\u001b[0m\n\u001b[1;32m     89\u001b[0m         partitioner=input_layer_partitioner):\n\u001b[1;32m     90\u001b[0m       net = feature_column_lib.input_layer(\n\u001b[0;32m---> 91\u001b[0;31m           features=features, feature_columns=feature_columns)\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hidden_units\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m       with variable_scope.variable_scope(\n",
      "\u001b[0;32m/Users/pyu18/anaconda/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36minput_layer\u001b[0;34m(features, feature_columns, weight_collections, trainable, cols_to_vars)\u001b[0m\n\u001b[1;32m    275\u001b[0m   \"\"\"\n\u001b[1;32m    276\u001b[0m   return _internal_input_layer(features, feature_columns, weight_collections,\n\u001b[0;32m--> 277\u001b[0;31m                                trainable, cols_to_vars)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pyu18/anaconda/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36m_internal_input_layer\u001b[0;34m(features, feature_columns, weight_collections, trainable, cols_to_vars, scope)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mweight_collections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_collections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             trainable=trainable)\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0mnum_elements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pyu18/anaconda/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36m_get_dense_tensor\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2295\u001b[0m     \u001b[0;31m# Feature has been already transformed. Return the intermediate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2296\u001b[0m     \u001b[0;31m# representation created by _transform_feature.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2297\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pyu18/anaconda/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2098\u001b[0m     \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Transforming feature_column %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m     \u001b[0mtransformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtransformed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Column {} is not supported.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pyu18/anaconda/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36m_transform_feature\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2264\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_transform_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2265\u001b[0;31m     \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2266\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2267\u001b[0m       raise ValueError(\n",
      "\u001b[0;32m/Users/pyu18/anaconda/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2091\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2092\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Feature {} is not in features dictionary.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2094\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_FeatureColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Feature x is not in features dictionary."
     ]
    }
   ],
   "source": [
    "accuracy_score = classifier.evaluate(input_fn=test_input_fn)[\"accuracy\"]\n",
    "print(accuracy_score)\n",
    "print(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score),\"model_type: \", model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_input(model_type):\n",
    "    if model_type == 'wide' or model_type == 'deep':\n",
    "        return tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": np.array(train_data)},\n",
    "        y=np.array(train_label),\n",
    "        num_epochs=None,\n",
    "        shuffle=True)\n",
    "    \n",
    "    else:\n",
    "    # Define the training inputs\n",
    "        return tf.estimator.inputs.numpy_input_fn(\n",
    "          x={\"wide\": np.array(train_data[:,0:4]), \"deep\": np.array(train_data[:,4:])},\n",
    "          y=np.array(train_label),\n",
    "        num_epochs=None,\n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model_type, model_dir):\n",
    "    classifier = build_estimator(model_type, model_dir)\n",
    "    train_input_fn = model_input(model_type)\n",
    "    classifier.train(input_fn=train_input_fn, steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_model_accuracy(model_type, model_dir):\n",
    "    accuracy_score = classifier.evaluate(input_fn=test_input_fn)[\"accuracy\"]\n",
    "    print(accuracy_score)\n",
    "    print(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score),\"model_type: \", model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-06-25-07:57:00\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/test_model15/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-06-25-07:57:29\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.537185, average_loss = 1.25748, global_step = 2000, loss = 160.957\n",
      "0.537185\n",
      "\n",
      "Test Accuracy: 0.537185\n",
      " model_type:  wide\n"
     ]
    }
   ],
   "source": [
    "# test_model_accuracy(model_type = \"wide\", \"/tmp/fv_a\")\n",
    "test_model_accuracy(model_type = \"wide\", model_dir = \"/tmp/fv_g\")\n",
    "# test_model_accuracy(model_type = \"wide+deep\", model_dir = \"/tmp/fv_e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Feature deep is not in features dictionary.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-543-61e42a2dd4b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   shuffle=False)\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mpredicted_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"classes\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pyu18/anaconda/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[1;32m    494\u001b[0m           input_fn, model_fn_lib.ModeKeys.PREDICT)\n\u001b[1;32m    495\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m--> 496\u001b[0;31m           features, None, model_fn_lib.ModeKeys.PREDICT, self.config)\n\u001b[0m\u001b[1;32m    497\u001b[0m       \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m       \u001b[0mall_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pyu18/anaconda/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pyu18/anaconda/lib/python3.6/site-packages/tensorflow/python/estimator/canned/dnn_linear_combined.py\u001b[0m in \u001b[0;36m_model_fn\u001b[0;34m(features, labels, mode, config)\u001b[0m\n\u001b[1;32m    400\u001b[0m           \u001b[0mdnn_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdnn_dropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m           \u001b[0minput_layer_partitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_layer_partitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m           config=config)\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     super(DNNLinearCombinedClassifier, self).__init__(\n",
      "\u001b[0;32m/Users/pyu18/anaconda/lib/python3.6/site-packages/tensorflow/python/estimator/canned/dnn_linear_combined.py\u001b[0m in \u001b[0;36m_dnn_linear_combined_model_fn\u001b[0;34m(features, labels, mode, head, linear_feature_columns, linear_optimizer, dnn_feature_columns, dnn_optimizer, dnn_hidden_units, dnn_activation_fn, dnn_dropout, input_layer_partitioner, config)\u001b[0m\n\u001b[1;32m    166\u001b[0m           \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdnn_dropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m           input_layer_partitioner=input_layer_partitioner)\n\u001b[0;32m--> 168\u001b[0;31m       \u001b[0mdnn_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdnn_logit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mlinear_parent_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'linear'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pyu18/anaconda/lib/python3.6/site-packages/tensorflow/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36mdnn_logit_fn\u001b[0;34m(features, mode)\u001b[0m\n\u001b[1;32m     89\u001b[0m         partitioner=input_layer_partitioner):\n\u001b[1;32m     90\u001b[0m       net = feature_column_lib.input_layer(\n\u001b[0;32m---> 91\u001b[0;31m           features=features, feature_columns=feature_columns)\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hidden_units\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m       with variable_scope.variable_scope(\n",
      "\u001b[0;32m/Users/pyu18/anaconda/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36minput_layer\u001b[0;34m(features, feature_columns, weight_collections, trainable, cols_to_vars)\u001b[0m\n\u001b[1;32m    275\u001b[0m   \"\"\"\n\u001b[1;32m    276\u001b[0m   return _internal_input_layer(features, feature_columns, weight_collections,\n\u001b[0;32m--> 277\u001b[0;31m                                trainable, cols_to_vars)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pyu18/anaconda/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36m_internal_input_layer\u001b[0;34m(features, feature_columns, weight_collections, trainable, cols_to_vars, scope)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mweight_collections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_collections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             trainable=trainable)\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0mnum_elements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pyu18/anaconda/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36m_get_dense_tensor\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2295\u001b[0m     \u001b[0;31m# Feature has been already transformed. Return the intermediate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2296\u001b[0m     \u001b[0;31m# representation created by _transform_feature.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2297\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pyu18/anaconda/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2098\u001b[0m     \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Transforming feature_column %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m     \u001b[0mtransformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtransformed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Column {} is not supported.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pyu18/anaconda/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36m_transform_feature\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2264\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_transform_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2265\u001b[0;31m     \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2266\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2267\u001b[0m       raise ValueError(\n",
      "\u001b[0;32m/Users/pyu18/anaconda/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2091\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2092\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Feature {} is not in features dictionary.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2094\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_FeatureColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Feature deep is not in features dictionary."
     ]
    }
   ],
   "source": [
    "# classify new samples\n",
    "new_samples = train_data[10:15]\n",
    "\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "  x={\"x\": new_samples},\n",
    "  num_epochs=1,\n",
    "  shuffle=False)\n",
    "\n",
    "predictions = list(classifier.predict(input_fn=predict_input_fn))\n",
    "predicted_classes = [p[\"classes\"] for p in predictions]\n",
    "\n",
    "print(\"New Samples, Class Predictions:    {}\\n\"\n",
    "      .format(predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/pyu18/Documents/ML_TF/Final_Project'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
